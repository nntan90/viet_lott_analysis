name: Crawl Power 6/55

on:
  schedule:
    # 17:15 UTC on T3, T5, T7 = 00:15 ICT on T4, T6, CN (next day after draw)
    # This matches when vietvudanh's data is pushed to Github
    - cron: '15 17 * * 2,4,6'
  workflow_dispatch:  # Allow manual trigger

jobs:
  crawl:
    name: Crawl Power 6/55 Results
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          python -c "
          import sys
          sys.path.insert(0, '.')
          from src.crawlers.power655_crawler import Power655Crawler
          from src.utils import supabase_client as db
          from src.notifications.telegram_notifier import notify_crawl
          from src.utils.logger import get_logger
          log = get_logger('crawl_action')

          crawler = Power655Crawler()
          result = crawler.fetch_latest()
          if not result:
              notify_crawl({'success': False, 'lottery_type': 'power_655', 'error': 'Fetch returned None'})
              sys.exit(1)

          existing = db.get_result_by_draw_id('power_655', result['draw_id'])
          if existing:
              log.info(f'draw_id={result[\"draw_id\"]} already in DB, skipping.')
              sys.exit(0)

          db.upsert_lottery_result(result)
          notify_crawl({**result, 'success': True, 'lottery_type': 'power_655',
                        'lottery_label': 'Power 6/55'})
          log.info('Crawl success.')
          "
